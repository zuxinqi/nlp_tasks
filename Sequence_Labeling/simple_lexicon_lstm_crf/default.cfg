[DEFAULT]
uerdict_path = ./userdict.txt
stopwords_path = ./stopwords.txt
tokenizer_name = pkuseg
[DATA_PROCESS]
file_path = ../数据准备/boson_ner_all_data.pkl
save_path = ./LCEE_boson.pkl
char_emb = /root/zxq/Flat-Lattice-Transformer-master/chinese/gigaword_chn.all.a2b.uni.ite50.vec
bichar_emb = /root/zxq/Flat-Lattice-Transformer-master/chinese/gigaword_chn.all.a2b.bi.ite50.vec
gaz_file = /root/zxq/Flat-Lattice-Transformer-master/chinese/ctb.50d.vec
train_file = /root/zxq/all_models/Sequence_Labeling/数据准备/train.char.bmes
dev_file = /root/zxq/all_models/Sequence_Labeling/数据准备/dev.char.bmes
test_file = /root/zxq/all_models/Sequence_Labeling/数据准备/test.char.bmes
[MODEL]
max_seq_length = 250
is_training = True
update_embedding = True
use_biword = False
use_char = False
use_count = True
hidden_size = 600
cell_nums = 1
use_cnn = False
kernel_nums = 300
kernel_size = 3
clip = 5
learning_rate = 0.0015
use_l2_regularization = False
use_decay_learning_rate = False
dropout_rate = 0.5
num_train_epochs = 15
batch_size = 16
shuffle = True
display_per_step = 100
evaluation_per_step = 500
require_improvement = 3
