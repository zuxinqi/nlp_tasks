[DEFAULT]
uerdict_path = ./userdict.txt
stopwords_path = ./stopwords.txt
tokenizer_name = single
[DATA_PROCESS]
file_path = ../数据准备/wz_data.pkl
save_path = ./Bert_wz.pkl
do_lower_case = True
vocab_file = /root/zxq/ner_extract/Bert+crf/chinese_roberta_wwm_ext_L-12_H-768_A-12/vocab.txt
[MODEL]
max_seq_length = 130
bert_config_file = /root/zxq/ner_extract/Bert+crf/chinese_roberta_wwm_ext_L-12_H-768_A-12/bert_config.json
init_checkpoint = /root/zxq/ner_extract/Bert+crf/chinese_roberta_wwm_ext_L-12_H-768_A-12/bert_model.ckpt
dropout_rate = 0.8
learning_rate = 3e-5
is_training = True
num_train_epochs = 12
batch_size = 32
warmup_proportion = 0.1
shuffle = True
display_per_step = 100
evaluation_per_step = 500
require_improvement = 3
