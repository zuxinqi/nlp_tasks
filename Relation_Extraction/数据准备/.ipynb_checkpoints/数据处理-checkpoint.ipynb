{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name):\n",
    "    data = []\n",
    "    with open(file_name, 'r', encoding=\"utf-8\") as f:\n",
    "        data_lines = f.readlines()\n",
    "        for data_line in data_lines:\n",
    "            data_dict = {}\n",
    "            data_line = json.loads(data_line)\n",
    "#             data_dict[\"text\"] = list(data_line[\"text\"])\n",
    "            data_dict[\"text\"] = [i.lower() for i in data_line[\"text\"]]\n",
    "#             data_dict[\"text\"] = \"\".join([i for i in data_line[\"text\"] if i.split()!=[]])\n",
    "            data_dict[\"triple_list\"] = []\n",
    "            for spo in data_line[\"spo_list\"]:\n",
    "#                 sub = list(spo[\"subject\"])\n",
    "                sub = [i.lower() for i in spo[\"subject\"]]\n",
    "#                 sub = \"\".join([i for i in sub if i.split()!=[]])\n",
    "                rela = spo[\"subject_type\"]+\"/\"+spo[\"object_type\"]+\"/\"+spo[\"predicate\"]\n",
    "#                 obj = list(spo[\"object\"])\n",
    "                obj = [i.lower() for i in spo[\"object\"]]\n",
    "#                 obj = \"\".join([i for i in obj if i.split()!=[]])\n",
    "                data_dict[\"triple_list\"].append([sub,rela,obj])\n",
    "            data.append(data_dict)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = parse_data(\"./dev_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = parse_data(\"./train_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relatons = []\n",
    "for data in train_data:\n",
    "    for i in data[\"triple_list\"]:\n",
    "        all_relatons.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "影视作品/人物/主演    56162\n",
      "图书作品/人物/作者    33853\n",
      "歌曲/人物/歌手    25605\n",
      "影视作品/人物/导演    22007\n",
      "人物/Date/出生日期    18793\n",
      "书籍/出版社/出版社    17709\n",
      "人物/地点/出生地    16553\n",
      "网络小说/网站/连载网站    12877\n",
      "人物/国家/国籍    12261\n",
      "人物/Text/民族    11533\n",
      "人物/学校/毕业院校    11516\n",
      "歌曲/音乐专辑/所属专辑    10402\n",
      "生物/目/目    10342\n",
      "歌曲/人物/作曲    9607\n",
      "企业/Date/成立日期    9107\n",
      "歌曲/人物/作词    9046\n",
      "影视作品/人物/编剧    6667\n",
      "影视作品/企业/出品公司    6419\n",
      "人物/人物/父亲    4701\n",
      "机构/Date/成立日期    3799\n",
      "人物/人物/妻子    3531\n",
      "人物/人物/丈夫    3523\n",
      "影视作品/Date/上映时间    3522\n",
      "人物/人物/母亲    3516\n",
      "历史人物/Text/朝代    3433\n",
      "人物/Number/身高    2905\n",
      "历史人物/Text/字    2733\n",
      "企业/地点/总部地点    2466\n",
      "人物/地点/祖籍    1817\n",
      "历史人物/Text/号    1551\n",
      "电视综艺/人物/主持人    1511\n",
      "电视综艺/人物/嘉宾    1368\n",
      "影视作品/人物/制片人    1160\n",
      "机构/Text/简称    1008\n",
      "行政区/气候/气候    920\n",
      "行政区/Number/面积    660\n",
      "企业/人物/创始人    633\n",
      "景点/城市/所在城市    575\n",
      "影视作品/作品/改编自    553\n",
      "机构/Number/占地面积    502\n",
      "行政区/Number/人口数量    409\n",
      "国家/城市/首都    397\n",
      "企业/Number/注册资本    397\n",
      "地点/Number/海拔    383\n",
      "企业/人物/董事长    368\n",
      "网络小说/人物/主角    250\n",
      "国家/语言/官方语言    145\n",
      "学科专业/Text/专业代码    26\n",
      "行政区/Text/邮政编码    25\n",
      "学科专业/Number/修业年限    20\n"
     ]
    }
   ],
   "source": [
    "# 统计标签个数\n",
    "all_relaton_dick = {}\n",
    "for i in all_relatons:\n",
    "    if i not in all_relaton_dick:\n",
    "        all_relaton_dick[i] = 1\n",
    "    else:\n",
    "        all_relaton_dick[i] += 1\n",
    "all_relaton_sorted_list = sorted(all_relaton_dick.items(),key=lambda x:x[1],reverse=True)\n",
    "for i in all_relaton_sorted_list:\n",
    "    print(i[0]+\"    \"+str(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7582\n",
      "65142\n",
      "59814\n",
      "36083\n",
      "3724\n",
      "764\n"
     ]
    }
   ],
   "source": [
    "# 查看数据长度\n",
    "n = 0\n",
    "m = 0\n",
    "k = 0\n",
    "l = 0\n",
    "p = 0\n",
    "h = 0\n",
    "for data in train_data:\n",
    "    snentence_2 = data[\"text\"]\n",
    "    length = len(snentence_2)\n",
    "    if length <= 20:\n",
    "        n += 1\n",
    "    elif length>20 and length<=40:\n",
    "        m += 1\n",
    "    elif length>40 and length<=70:\n",
    "        k += 1\n",
    "    elif length>70 and length<=130:\n",
    "        l += 1\n",
    "    elif length>130 and length<=200:\n",
    "        p += 1\n",
    "    else:\n",
    "        h += 1\n",
    "print(n)\n",
    "print(m)\n",
    "print(k)\n",
    "print(l)\n",
    "print(p)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接从训练集里面摘取数据，选择人物相关\n",
    "all_train_data = []\n",
    "allow_relation = [\"人物/Date/出生日期\",\"人物/地点/出生地\",\"人物/国家/国籍\",\"人物/学校/毕业院校\"]\n",
    "for data in train_data:\n",
    "    flag = 0\n",
    "    if len(data[\"text\"])>120:\n",
    "        continue\n",
    "    new_data = {\"text\":data[\"text\"],\"triple_list\":[]}\n",
    "    triple_list = data[\"triple_list\"]\n",
    "    for i in triple_list:\n",
    "        if i[1] in allow_relation:\n",
    "            flag = 1\n",
    "            new_data[\"triple_list\"].append(i)\n",
    "    if flag == 1:\n",
    "        all_train_data.append(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relatons = []\n",
    "for data in all_train_data:\n",
    "    for i in data[\"triple_list\"]:\n",
    "        all_relatons.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人物/Date/出生日期    18150\n",
      "人物/地点/出生地    16062\n",
      "人物/国家/国籍    11438\n",
      "人物/学校/毕业院校    11082\n"
     ]
    }
   ],
   "source": [
    "# 统计标签个数\n",
    "all_relaton_dick = {}\n",
    "for i in all_relatons:\n",
    "    if i not in all_relaton_dick:\n",
    "        all_relaton_dick[i] = 1\n",
    "    else:\n",
    "        all_relaton_dick[i] += 1\n",
    "all_relaton_sorted_list = sorted(all_relaton_dick.items(),key=lambda x:x[1],reverse=True)\n",
    "for i in all_relaton_sorted_list:\n",
    "    print(i[0]+\"    \"+str(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2041\n",
      "10968\n",
      "13746\n",
      "9171\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 查看数据长度\n",
    "n = 0\n",
    "m = 0\n",
    "k = 0\n",
    "l = 0\n",
    "p = 0\n",
    "h = 0\n",
    "for data in all_train_data:\n",
    "    snentence_2 = data[\"text\"]\n",
    "    length = len(snentence_2)\n",
    "    if length <= 20:\n",
    "        n += 1\n",
    "    elif length>20 and length<=40:\n",
    "        m += 1\n",
    "    elif length>40 and length<=70:\n",
    "        k += 1\n",
    "    elif length>70 and length<=120:\n",
    "        l += 1\n",
    "    elif length>120 and length<=200:\n",
    "        p += 1\n",
    "    else:\n",
    "        h += 1\n",
    "print(n)\n",
    "print(m)\n",
    "print(k)\n",
    "print(l)\n",
    "print(p)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接从训练集里面摘取数据，选择人物相关\n",
    "all_test_data = []\n",
    "allow_relation = [\"人物/Date/出生日期\",\"人物/地点/出生地\",\"人物/国家/国籍\",\"人物/学校/毕业院校\"]\n",
    "for data in test_data:\n",
    "    flag = 0\n",
    "    if len(data[\"text\"])>120:\n",
    "        continue\n",
    "    new_data = {\"text\":data[\"text\"],\"triple_list\":[]}\n",
    "    triple_list = data[\"triple_list\"]\n",
    "    for i in triple_list:\n",
    "        if i[1] in allow_relation:\n",
    "            flag = 1\n",
    "            new_data[\"triple_list\"].append(i)\n",
    "    if flag == 1:\n",
    "        all_test_data.append(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation2id = {j:i for i,j in enumerate(sorted(allow_relation))}\n",
    "id2relation = {j:i for i,j in relation2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lic2019_relation_extraction_data.pkl\", 'wb') as f:\n",
    "    pickle.dump([all_train_data,all_test_data,relation2id,id2relation], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"哇哇哇哇哇阿斯顿啊大苏打发\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "啊大苏打发\n",
      "顿啊大苏打\n",
      "斯顿啊大苏\n",
      "阿斯顿啊大\n",
      "哇阿斯顿啊\n",
      "哇哇阿斯顿\n",
      "哇哇哇阿斯\n",
      "哇哇哇哇阿\n",
      "哇哇哇哇哇\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(a),0,-1):\n",
    "    print(a[i-5:i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    all_test_data = []\n",
    "    with open(\"./dev_data.json\", 'r', encoding=\"utf-8\") as f:\n",
    "        data_lines = f.readlines()\n",
    "        for data_line in data_lines:\n",
    "            data_dict = {}\n",
    "            data_line = json.loads(data_line)\n",
    "            data_dict[\"text\"] =  data_line[\"text\"]\n",
    "            data_dict[\"triple_list\"] = []\n",
    "            for spo in data_line[\"spo_list\"]:\n",
    "                sub = [i.lower() for i in spo[\"subject\"]]\n",
    "                rela = spo[\"subject_type\"]+\"/\"+spo[\"object_type\"]+\"/\"+spo[\"predicate\"]\n",
    "                obj = [i.lower() for i in spo[\"object\"]]\n",
    "                data_dict[\"triple_list\"].append([sub,rela,obj])\n",
    "            all_test_data.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接从训练集里面摘取数据，选择人物相关\n",
    "display_test_data = []\n",
    "allow_relation = [\"人物/Date/出生日期\",\"人物/地点/出生地\",\"人物/国家/国籍\",\"人物/学校/毕业院校\"]\n",
    "for data in all_test_data:\n",
    "    flag = 0\n",
    "    if len(data[\"text\"])>120:\n",
    "        continue\n",
    "    new_data = {\"text\":data[\"text\"],\"triple_list\":[]}\n",
    "    triple_list = data[\"triple_list\"]\n",
    "    for i in triple_list:\n",
    "        if i[1] in allow_relation:\n",
    "            flag = 1\n",
    "            new_data[\"triple_list\"].append(i)\n",
    "    if flag == 1:\n",
    "        display_test_data.append(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查尔斯·阿兰基斯（Charles Aránguiz），1989年4月17日出生于智利圣地亚哥，智利职业足球运动员，司职中场，效力于德国足球甲级联赛勒沃库森足球俱乐部\n",
      "查尔斯·阿兰基斯 人物/地点/出生地 圣地亚哥\n",
      "查尔斯·阿兰基斯 人物/Date/出生日期 1989年4月17日\n",
      "\n",
      "马志舟，1907年出生，陕西三原人，汉族，中国共产党，任红四团第一连连长，1907年逝世\n",
      "马志舟 人物/国家/国籍 中国\n",
      "马志舟 人物/Date/出生日期 1907\n",
      "\n",
      "世界百科大全总编彭友定义本词条为 人物总类 董事长分类概述 1朱明宏的基本情况男 汉族 1968年6月生 浙江义乌人11现任 金华市发展和改革委员会副主任1拟任 金华市现代服务业投资发展有限公司董事长\n",
      "朱明宏 人物/地点/出生地 浙江义乌\n",
      "\n",
      "田承冉 男，1952年生，汉族，山东桓台人，共党员\n",
      "田承冉 人物/地点/出生地 山东桓台\n",
      "田承冉 人物/Date/出生日期 1952\n",
      "\n",
      "Chanda Mushili,赞比亚籍运动员\n",
      "chanda mushili 人物/国家/国籍 赞比亚\n",
      "\n",
      "莫迪博·迪亚基特1987年3月2日出生于法国的赖恩堡，身高192cm，司职后卫，双脚技术均衡，身披21号战袍，曾效力于佩斯卡拉，现效力于拉齐奥队\n",
      "莫迪博·迪亚基特 人物/Date/出生日期 1987年3月2日\n",
      "莫迪博·迪亚基特 人物/地点/出生地 赖恩堡\n",
      "\n",
      "布丹出生于1824年的法国画家\n",
      "布丹 人物/国家/国籍 法国\n",
      "布丹 人物/Date/出生日期 1824\n",
      "\n",
      "马红宝 男 汉族，1949年8月生，浙江省长兴县人，1978年8月加入中国共产党，1967年9月参加工作，大普文化\n",
      "马红宝 人物/国家/国籍 中国\n",
      "马红宝 人物/地点/出生地 浙江省长兴\n",
      "\n",
      "吕雅娟，博士毕业于哈尔滨工业大学，现任百度高级研究员\n",
      "吕雅娟 人物/学校/毕业院校 哈尔滨工业大学\n",
      "\n",
      "前秦世祖宣昭皇帝苻坚（338年－385年10月16日），字永固，又字文玉，小名坚头，氐族，略阳临渭（今甘肃秦安）人，十六国时期前秦的君主，公元357－385年在位\n",
      "苻坚 人物/Date/出生日期 338年\n",
      "苻坚 人物/地点/出生地 略阳临渭\n",
      "\n",
      "个人信息韦爱萍，女，汉族，1986年毕业于西北大学中文系，获文学学士学位\n",
      "韦爱萍 人物/学校/毕业院校 西北大学\n",
      "\n",
      "张书文，男，1964年3月出生，汉族，湖北随州广水市人，在职研究生，会计师，审计师，民建会员，1982年8月参加工作\n",
      "张书文 人物/Date/出生日期 1964年3月\n",
      "张书文 人物/地点/出生地 湖北随州广水市\n",
      "\n",
      "夏振锟，男，生于江苏省连云港，毕业于苏州农业大学\n",
      "夏振锟 人物/地点/出生地 江苏省连云港\n",
      "夏振锟 人物/学校/毕业院校 苏州农业大学\n",
      "\n",
      "李欣，毕业于东京海洋大学，现为 上海海洋大学讲师\n",
      "李欣 人物/学校/毕业院校 东京海洋大学\n",
      "\n",
      "人物简介蔡长风（1910—2001），江西省吉水县人\n",
      "蔡长风 人物/地点/出生地 江西\n",
      "蔡长风 人物/Date/出生日期 1910\n",
      "\n",
      "贺捷生，1935年11月1日生，贺龙同志的女儿，湖南省桑植县人，中国人民解放军少将，军事科学院军事百科研究部部长，军旅作家\n",
      "贺捷生 人物/国家/国籍 中国\n",
      "贺捷生 人物/Date/出生日期 1935年11月1日\n",
      "\n",
      "人物简介黄兴兰，女，医学学士，1983年毕业于四川医学院医学系，毕业后留校工作至今\n",
      "黄兴兰 人物/学校/毕业院校 四川医学院\n",
      "\n",
      "Amrane,阿尔及利亚籍运动员\n",
      "amrane 人物/国家/国籍 阿尔及利亚\n",
      "\n",
      "基本资料球员:阿梅素  生日:1980年11月22日  身高:171cm  球衣号码:999  国籍:加纳  效力球队:梅赫伦  场上位置:中场球队阵容前锋  云丹贝治,尼克拉斯\n",
      "阿梅素 人物/国家/国籍 加纳\n",
      "阿梅素 人物/Date/出生日期 1980年11月22日\n",
      "\n",
      "杨维桢（1296—1370），元末明初著名诗人、文学家、书画家和戏曲家\n",
      "杨维桢 人物/Date/出生日期 1296\n",
      "\n",
      "《17》1是加拿大歌手艾薇儿·拉维尼（Avril Lavigne）J Kash，Martin Johnson共同创作并收录于艾薇儿第五张同名专辑《Avril Lavigne》的一首歌曲\n",
      "艾薇儿 人物/国家/国籍 加拿大\n",
      "\n",
      "马克西·莫拉雷斯（Maximiliano Morales），男，1987年02月27日出生，阿根廷足球运动员，身高1米60，体重53公斤，绰号“小巨人”，是一名足球运动员，2011年加盟意大利亚特兰大队\n",
      "马克西·莫拉雷斯 人物/国家/国籍 阿根廷\n",
      "马克西·莫拉雷斯 人物/Date/出生日期 1987年02月27日\n",
      "\n",
      "汪景宽（1963-），男，满族，辽宁省凤城人，中共党员\n",
      "汪景宽 人物/Date/出生日期 1963\n",
      "\n",
      "付成双，男，1970年出生于山东省滨州市惠民县，现为南开大学历史学院副院长、世界近现代史专业教授、博士生导师\n",
      "付成双 人物/地点/出生地 山东省滨州市惠民县\n",
      "付成双 人物/Date/出生日期 1970\n",
      "\n",
      "大学：中南大学 （2012年—2016年）1所获荣誉高中时期，程天豹代表江苏省、南京市参加全国中学生运动会的篮球赛，所在的队伍拿到到全国第二成绩\n",
      "程天豹 人物/学校/毕业院校 中南大学\n",
      "\n",
      "王饭包，（1901－1936），福建省寿宁县竹管垄乡刘坪村人\n",
      "王饭包 人物/Date/出生日期 1901\n",
      "\n",
      "基本资料球员:尼林  生日:1986年9月20日  身高:180cm  加盟日期:2011-7  球衣号码:30  国籍:巴西  效力球队:华拉特莎  场上位置:中场球队阵容前锋  卡斯特丁诺夫,N\n",
      "尼林 人物/国家/国籍 巴西\n",
      "尼林 人物/Date/出生日期 1986年9月20日\n",
      "\n",
      "金一宁，男，出生于1972年2月，哈尔滨商业大学计算机与信息工程学院副教授，计算机软件基础教研室主任\n",
      "金一宁 人物/Date/出生日期 1972年2月\n",
      "金一宁 人物/学校/毕业院校 哈尔滨商业大学\n",
      "\n",
      "3  年5月4日上午，中国官方发布消息，国务院总理李克强此次出访非洲，夫人程虹随行\n",
      "程虹 人物/国家/国籍 中国\n",
      "李克强 人物/国家/国籍 中国\n",
      "\n",
      "杨力革，男，汉族，1966年4月生，湖南益阳人，1987年7月参加工作，1992年10月入党，在职研究生学历（2004年7月新疆自治区党委党校领导干部研究生班工商管理专业毕业）\n",
      "杨力革 人物/Date/出生日期 1966年4月\n",
      "杨力革 人物/地点/出生地 湖南益阳\n",
      "\n",
      "出版画集《今日中国美术丛书·党震》、《中国当代青年画家—党震》、《党震作品集》、  《素描经典·党震作品集》\n",
      "党震 人物/国家/国籍 中国\n",
      "\n",
      "基本资料球员:尼科斯  生日:1984年6月24日  身高:182cm  体重:75kg  球衣号码:8  国籍:塞浦路斯  效力球队:艾米斯  场上位置:中场球队阵容前锋  K\n",
      "尼科斯 人物/Date/出生日期 1984年6月24日\n",
      "尼科斯 人物/国家/国籍 塞浦路斯\n",
      "\n",
      "黄炳华，浙江诸暨人，1938年出生，1963年8月浙江大学毕业后入伍，第二炮兵某设计所原副总工程师\n",
      "黄炳华 人物/Date/出生日期 1938\n",
      "黄炳华 人物/学校/毕业院校 浙江大学\n",
      "黄炳华 人物/地点/出生地 浙江诸暨\n",
      "\n",
      "申德振，男，汉族，1959年9月出生，辽宁省铁岭市人\n",
      "申德振 人物/地点/出生地 辽宁省铁岭市\n",
      "申德振 人物/Date/出生日期 1959年9月\n",
      "\n",
      "赵澜 福建师范大学社会历史学院历史系副教授，，1988年复旦大学历史系本科毕业，1992年获历史学硕士学位\n",
      "赵澜 人物/学校/毕业院校 复旦大学\n",
      "\n",
      "侯云凌，女，皮肤科副主任 ， 毕业于武汉同济医科大学临床医疗系，先后在武汉协和医院皮肤科、湘雅医院皮肤科工作多年\n",
      "侯云凌 人物/学校/毕业院校 武汉同济医科大学\n",
      "\n",
      "江里程，男，汉族，1956年9月生，浙江宁波人，1976年10月加入中国共产党，1974年12月参加工作，镇江农机学院农业机械化专业毕业，在职研究生学历，管理学博士学位1\n",
      "江里程 人物/学校/毕业院校 镇江农机学院\n",
      "江里程 人物/国家/国籍 中国\n",
      "江里程 人物/地点/出生地 浙江宁波\n",
      "\n",
      "3传奇故事老家江西萍乡人民对宋侃夫的最初了解，是发生在1930年的一件传奇故事\n",
      "宋侃夫 人物/地点/出生地 江西萍乡\n",
      "\n",
      "人物生平徐海，1969年生于北京，1992年毕业于中央美术学院国画系本科，2010年获美术学博士学位（导师王镛教授，中国书画印创作研究方向）\n",
      "王镛 人物/国家/国籍 中国\n",
      "徐海 人物/地点/出生地 北京\n",
      "徐海 人物/学校/毕业院校 中央美术学院\n",
      "徐海 人物/Date/出生日期 1969\n",
      "\n",
      "《股票分析指标大全》是2000年5月1日中国经济出版社出版的图书，作者是张泽宇\n",
      "张泽宇 人物/国家/国籍 中国\n",
      "\n",
      "年出生的杨福东，被认为是中国当代影像艺术家中最重要的代表人物之一\n",
      "杨福东 人物/国家/国籍 中国\n",
      "\n",
      "司马岳（322年―344年），即晋康帝（342年―344年在位），东晋第四位皇帝，字世同，晋明帝司马绍次子，晋成帝司马衍同母弟1，母明穆皇后庾文君\n",
      "司马岳 人物/Date/出生日期 322\n",
      "\n",
      "黄主文，1941年8月20日出生，台湾省桃园县人，台湾大学法律系毕业、司法官训练所第8期结业、司法官高等考试及格\n",
      "黄主文 人物/地点/出生地 台湾省桃园县\n",
      "黄主文 人物/学校/毕业院校 台湾大学\n",
      "黄主文 人物/Date/出生日期 1941年8月20日\n",
      "\n",
      "邱鸿理，毕业于中南工业大学，高级工程师技术职称，曾任中国水利学会施工专业委员会爆破学组成员\n",
      "邱鸿理 人物/学校/毕业院校 中南工业大学\n",
      "邱鸿理 人物/国家/国籍 中国\n",
      "\n",
      "王凡恩,男，1969年出生，河南民权人，1991年7月毕业于河南大学地理教育专业，获学士学位，现任商丘师范学院经济与管理学院经济学专业讲师\n",
      "王凡恩 人物/Date/出生日期 1969\n",
      "王凡恩 人物/地点/出生地 河南民权\n",
      "\n",
      "人物介绍邱宏光，男，1972年5月出生，湖北新洲人，2武汉大学中国现当代文学博士毕业\n",
      "邱宏光 人物/学校/毕业院校 武汉大学\n",
      "邱宏光 人物/地点/出生地 湖北新洲\n",
      "\n",
      "刘智（1669—1764年），字介廉，号一斋，清上元（南京）人，为清初回族伊斯兰教著名学者著作家，据刘智研究专家马在渊先生考证，刘智高寿达96岁，详见《刘介廉先生编年考》\n",
      "刘智 人物/地点/出生地 南京\n",
      "刘智 人物/Date/出生日期 1669\n",
      "\n",
      "中国共产党第十九届中央委员会候补委员7任免信息2017年7月31日下午，中国银行总行召开干部大会，宣布中央关于中国银行主要负责同志调整的决定，陈四清担任中国银行党委书记\n",
      "陈四清 人物/国家/国籍 中国\n",
      "\n",
      "毛伟林人气指数:30无代表图像姓名：毛伟林  英文名：  性别：男  国籍：中国  出生城市：杭州  出生日期：  身高：186cm  体重：85kg  场上位置：前锋  场上编号：13  所属团队：  曾效力团队：\n",
      "毛伟林 人物/国家/国籍 中国\n",
      "\n",
      "徐雷，男，1974年5月出生，汉族，上海市人，全日制大学，工程硕士，工程师，1996年7月参加工作，1996年4月加入中国共产党\n",
      "徐雷 人物/Date/出生日期 1974年5月\n",
      "\n",
      "桑童，女，汉族，1981年6月生， 2003年毕业于山东工艺美术学院服装设计与工程专业，本科学历，获文学学士学位，现任贵州民族学院美术学院教师，苏州大学材料工程学院（服装设计与工程）专业学位在读研究生\n",
      "桑童 人物/学校/毕业院校 山东工艺美术学院\n",
      "\n",
      "张四维（1526—1585年）字子维，号凤磐，蒲州风陵乡人（今属芮城），嘉靖三十二年（1553）进士，授编修\n",
      "张四维 人物/地点/出生地 蒲州风陵乡\n",
      "张四维 人物/Date/出生日期 1526\n",
      "\n",
      "人物生平王嘉瑞，1989年12月加入中国共产党，1984年5月参加工作，大专学历\n",
      "王嘉瑞 人物/国家/国籍 中国\n",
      "\n",
      "张柏芝，1980年5月24日出生于中国香港，毕业于澳大利亚Rmit Holmes College，中国香港女演员、歌手\n",
      "张柏芝 人物/地点/出生地 中国香港\n",
      "张柏芝 人物/Date/出生日期 1980年\n",
      "张柏芝 人物/Date/出生日期 1980年5月24日\n",
      "张柏芝 人物/国家/国籍 中国\n",
      "张柏芝 人物/学校/毕业院校 澳大利亚rmit holmes college\n",
      "\n",
      "任长方，1930年生，中共党员，主任医师\n",
      "任长方 人物/Date/出生日期 1930\n",
      "\n",
      "冷家骥，字展麒，山东招远人\n",
      "冷家骥 人物/地点/出生地 山东招远\n",
      "\n",
      "毛保祥，男，汉族，1960年5月生，云南宁洱人，1984年4月加入中国共产党，1980年8月参加工作，云南省委党校国民经济管理专业毕业，研究生学历\n",
      "毛保祥 人物/学校/毕业院校 云南省委党校\n",
      "毛保祥 人物/国家/国籍 中国\n",
      "\n",
      "李庭桂，男，汉族，1914年生，河北藁城人\n",
      "李庭桂 人物/地点/出生地 河北藁城\n",
      "李庭桂 人物/Date/出生日期 1914\n",
      "\n",
      "《不怕贼惦记》是许传海自编自导的一部剧情电影，由吴刚、岳秀清、应采儿、张馨予等领衔主演，该片于2011年12月9日中国上映\n",
      "吴刚 人物/国家/国籍 中国\n",
      "\n",
      "王纪兴，男，1927年3月出生，河北定州人\n",
      "王纪兴 人物/Date/出生日期 1927年3月\n",
      "\n",
      "接触电商陈俊龙有幸成为中国第一批接触电商的年青人，2006年他就在深圳帮老板打理网店\n",
      "陈俊龙 人物/国家/国籍 中国\n",
      "\n",
      "施隆壮，1950年1月生，浙江人\n",
      "施隆壮 人物/地点/出生地 浙江\n",
      "\n",
      "个人简介钟旭秋，男，1947年出生，中共党员，1982年西南科技大学（原四川建筑材料工业学院）电化系自动化专业毕业，工学学士，副研究员\n",
      "钟旭秋 人物/Date/出生日期 1947\n",
      "\n",
      "段润尧据公开信息显示，段润尧本科和博士就读于清华大学计算机系，师从应明生教授\n",
      "段润尧 人物/学校/毕业院校 清华大学\n",
      "\n",
      "吴锦怀  1948年出生，广东东莞人，中共党员，口腔科技师，东莞市道溶医院院长办公室主任，中华医学会会员，中国氟研究会会员\n",
      "吴锦怀 人物/Date/出生日期 1948\n",
      "\n",
      "4、诸葛亮（三国时期蜀汉丞相）诸葛亮（181年－234年10月8日），字孔明，号卧龙（也作伏龙），汉族，徐州琅琊阳都（今山东临沂市沂南县）人，三国时期蜀汉丞相，杰出的政治家、军事家、外交家、文学家、书法家、发明家\n",
      "诸葛亮 人物/Date/出生日期 181年\n",
      "诸葛亮 人物/地点/出生地 琅琊阳都\n",
      "\n",
      "郑广镐生于韩国大田市，毕业于韩国汉城艺术专科学校以及汉城国立大学艺术创作研究所，郑氏曾参加纽约军械库艺术博览会以及芝加哥艺术博览会，其作品自2001年以来连续在瑞士巴赛尔艺廊博览会中展出，获得欧洲艺评及藏家的喜爱与热烈回响\n",
      "郑广镐 人物/学校/毕业院校 韩国汉城艺术专科学校\n",
      "郑广镐 人物/地点/出生地 韩国大田市\n",
      "\n",
      "朱泰墱(1416－1467)：朱肇煇嫡次子，首任巨野王\n",
      "朱泰墱 人物/Date/出生日期 1416\n",
      "\n",
      "朱利安·格雷，英格兰人，1979年9月21出生，身高185CM，体重70KG，足球运动员，曾以中场效力于水晶宫足球俱乐部\n",
      "朱利安·格雷 人物/国家/国籍 英格兰\n",
      "朱利安·格雷 人物/Date/出生日期 1979年9月\n",
      "\n",
      "姓名： 臧春梅1996——1999北京师范大学化学系研究生毕业工作单位：中国人民大学附属中学（1999——）职称：高级教师\n",
      "臧春梅 人物/学校/毕业院校 北京师范大学\n",
      "\n",
      "后来我从事现代中国思想史研究，更发现刘再复是一个绕不开的名字\n",
      "刘再复 人物/国家/国籍 中国\n",
      "\n",
      "张公社，男，1960年3月生，1983年7月毕业于江汉石油学院采油工程专业，同年留校任教，1994年7月研究生毕业于西南石油学院，获油气田开发工程专业硕士学位，1994年12月晋升为副教授，1999年12月晋升为教授，2014年被评为博导\n",
      "张公社 人物/Date/出生日期 1960年3月\n",
      "张公社 人物/学校/毕业院校 西南石油学院\n",
      "\n",
      "约瑟夫·杨（Joseph Young），1992年6月27日出生于美国德克萨斯州休斯敦（Houston, TX），美国职业篮球运动员，司职控球后卫，效力于NBA印第安纳步行者队\n",
      "约瑟夫·杨 人物/地点/出生地 美国德克萨斯州休斯敦\n",
      "约瑟夫·杨 人物/国家/国籍 美国\n",
      "约瑟夫·杨 人物/Date/出生日期 1992年6月27日\n",
      "\n",
      "基本信息姓　名：黄宗友  性　别：男  民　族：汉族  籍　贯：湖北谷城  出生年月：1892年  牺牲日期：1928年08月20日人物简介1926年7月，加入中国共产党\n",
      "黄宗友 人物/Date/出生日期 1892\n",
      "\n",
      "人物生平王钦若（962年－1025年），字定国，谥“文穆”，临江军新喻（今江西省新余市东门王家）人\n",
      "王钦若 人物/Date/出生日期 962年\n",
      "王钦若 人物/地点/出生地 临江军新喻\n",
      "王钦若 人物/Date/出生日期 962\n",
      "\n",
      "奥格涅·弗拉涅斯：本名Ognjen Vranjes，波黑人，1989年10月24日出生在巴尼亚卢卡（波黑），身高182CM，体重75KG\n",
      "奥格涅·弗拉涅斯 人物/地点/出生地 巴尼亚卢卡\n",
      "奥格涅·弗拉涅斯 人物/Date/出生日期 1989年10月24日\n",
      "\n",
      "杨群德，男，1968年10月出生，汉族，广西荔浦县人，中共党员，1990年7月参加工作，1992年11月加入中国共产党，大学本科学历，现任荔浦县工商局副局长、党组成员\n",
      "杨群德 人物/Date/出生日期 1968年10月\n",
      "\n",
      "廖鹏，男，汉族，国籍中国，江苏省美术馆副馆长\n",
      "廖鹏 人物/国家/国籍 中国\n",
      "\n",
      "《故事本中国哲学史》是2002年上海古籍出版社出版的图书，作者是唐志龙\n",
      "唐志龙 人物/国家/国籍 中国\n",
      "\n",
      "石先前 1945年9月 生人，1968年7月毕业于中南工业大学电气化专业，1968年9月分配在水城钢铁公司工作，1975年2月加入中国共产党，高级工程师\n",
      "石先前 人物/学校/毕业院校 中南工业大学\n",
      "\n",
      "张家瑜（1915 —1968），汉族，江苏扬州人，是张嗣昌长子、医学家\n",
      "张家瑜 人物/地点/出生地 江苏扬州\n",
      "张家瑜 人物/Date/出生日期 1915\n",
      "\n",
      "苏莉是人名，同名的有衡阳市公安局跳楼女青年苏莉、华中科技大学教师苏莉、图书馆副研究馆员苏莉、武汉大学教授苏莉\n",
      "苏莉 人物/学校/毕业院校 武汉大学\n",
      "\n",
      "人物生平吴氏太极拳 宗师 吴鉴泉 次子吴公藻(1900-1985)，家学渊源1尤以理论见长，著作甚多\n",
      "吴公藻 人物/Date/出生日期 1900\n",
      "\n",
      "陈荣发（1903－1932），福建省龙岩县（今龙岩市新罗区）东肖镇中民村人\n",
      "陈荣发 人物/地点/出生地 福建省龙岩县\n",
      "\n",
      "满都拉，男，蒙古族，1962年11月出生，内蒙古自治区巴彦淖尔市乌拉特中旗人，1986年9月参加工作，1993年6月入党，内蒙古农业大学毕业，硕士研究生学历\n",
      "满都拉 人物/Date/出生日期 1962年11月\n",
      "满都拉 人物/地点/出生地 巴彦淖尔市乌拉特中旗\n",
      "满都拉 人物/地点/出生地 内蒙古\n",
      "满都拉 人物/学校/毕业院校 内蒙古农业大学\n",
      "\n",
      "2005年1月23日，在人民大会堂召开的 “2004中国十大影响力品牌”新闻发布会上，富安娜荣膺“中国行业十大影响力品牌”，林国芳董事长获得“中国品牌建设十大杰出企业家”荣誉称号\n",
      "林国芳 人物/国家/国籍 中国\n",
      "\n",
      "于学波，男，汉族，1969年1月生，1990年9月参加工作，中共党员，大学学历\n",
      "于学波 人物/Date/出生日期 1969年1月\n",
      "\n",
      "《拥有神之舌的男人》是日本TBS电视台2016年播出的电视连续剧，由堤幸彦、伊藤雄介、加藤新执导，樱井武晴编剧，向井理主演，木村文乃、佐藤二朗出演，于2016年7月8日首播\n",
      "加藤新 人物/国家/国籍 日本\n",
      "\n",
      "原名刘建运，1907年生于山东临沂市\n",
      "刘建运 人物/地点/出生地 山东临沂市\n",
      "刘建运 人物/Date/出生日期 1907\n",
      "\n",
      "伍嘉成，1993年7月18日出生于广东台山，毕业于星海音乐学院，是彭楚粤的师弟，团内主唱，队长之一\n",
      "彭楚粤 人物/学校/毕业院校 星海音乐学院\n",
      "伍嘉成 人物/Date/出生日期 1993年7月18日\n",
      "伍嘉成 人物/学校/毕业院校 星海音乐学院\n",
      "\n",
      "1918年，王甲本父母双亡后，得家族中四叔王怀仁资助，经父亲好友范石生介绍考进了云南陆军讲武堂第14期炮兵科，并于当年12月以全优的成绩毕业，在滇军统帅第一军顾品珍部下当兵，走上了报国之路\n",
      "王甲本 人物/学校/毕业院校 云南陆军讲武堂\n",
      "\n",
      "张耀东1998年毕业于哈尔滨工业大学汽车工程学院内燃机专业\n",
      "张耀东 人物/学校/毕业院校 哈尔滨工业大学\n",
      "\n",
      "因为其当年的老师对社会时事很感兴趣，这也感染了刘强东，他没有北京大学，而是选择了中国人民大学社会学系\n",
      "刘强东 人物/学校/毕业院校 中国人民大学\n",
      "\n",
      "20世纪初，中国妇女受教育及在社会上谋职是极为罕见的，最初朱洪元的外祖父在家中兴学，上学的只有家中的男性子弟，他的母亲在窗外听讲，接受了启蒙教育，后来风气开化，他的母亲入了学堂，由于成绩优异，一直得到免交学费的奖励\n",
      "朱洪元 人物/国家/国籍 中国\n",
      "\n",
      "基本资料球员:菲菲尔  生日:1986年10月19日  身高:176cm  体重:73kg  球衣号码:23  国籍:德国  效力球队:卓尼特斯  场上位置:中场  前度效力球队:德累斯顿  曾经效力球队:德累斯顿球队阵容前锋  A\n",
      "菲菲尔 人物/Date/出生日期 1986年10月19日\n",
      "菲菲尔 人物/国家/国籍 德国\n",
      "\n",
      "1942年5月，云南归化寺的枪声，是日军从缅甸畹町进入中国后遇到中国军队顽强反抗的枪声，它使正在病中的李根源兴奋不已，特写诗赞道：“长吏闻风走，八方惊分窜\n",
      "李根源 人物/国家/国籍 中国\n",
      "\n",
      "陈希，男，汉族，1976年8月于上海，全日制大学，经济学学士，管理学硕士，经济师，1999年7月参加工作，2002年2月，加入中国共产党\n",
      "陈希 人物/地点/出生地 上海\n",
      "陈希 人物/国家/国籍 中国\n",
      "\n",
      "张志友，男，汉族，天津宝坻人，1958年2月出生，市委党校大专学历，1984年4月入党，1981年1月参加工作\n",
      "张志友 人物/地点/出生地 天津宝坻\n",
      "\n",
      "管仲（约公元前723年－公元前645年），姬姓，管氏，名夷吾，字仲，谥敬，春秋时期法家代表人物，颍上人（今安徽颍上），周穆王的后代\n",
      "管仲 人物/地点/出生地 颍上\n",
      "\n",
      "潘卫东，男，中国矿业大学（北京）副教授\n",
      "潘卫东 人物/国家/国籍 中国\n",
      "潘卫东 人物/学校/毕业院校 中国矿业大学\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in display_test_data[:100]:\n",
    "    print(i[\"text\"])\n",
    "    for j in i[\"triple_list\"]:\n",
    "        print(\"\".join(j[0]),j[1],\"\".join(j[2]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [{(('布', '丹'), '人物/Date/出生日期', ('1', '8', '2', '4')), (('布', '丹'), '人物/地点/出生地', ('法', '国')), (('布', '丹'), '人物/国家/国籍', ('法', '国'))}, {(('杨', '维', '桢'), '人物/Date/出生日期', ('1', '2', '9', '6'))}, {(('张', '柏', '芝'), '人物/Date/出生日期', ('1', '9', '8', '0', '年', '5', '月', '2', '4', '日')), (('张', '柏', '芝'), '人物/国家/国籍', ('中', '国')), (('张', '柏', '芝'), '人物/地点/出生地', ('中', '国', '香', '港'))}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ((0, 2), (11, 13), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "11\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-8a9b626f4e81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i,j in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ca68dd2ac473>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "for s,o,r in ((0, 2), (11, 13), 1):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('张', '柏', '芝'),\n",
       "  '人物/Date/出生日期',\n",
       "  ('1', '9', '8', '0', '年', '5', '月', '2', '4', '日')),\n",
       " (('张', '柏', '芝'), '人物/国家/国籍', ('中', '国')),\n",
       " (('张', '柏', '芝'), '人物/地点/出生地', ('中', '国', '香', '港'))}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaa = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "        random_order = list(range(len(aaaa)))\n",
    "        np.random.seed(209)\n",
    "        np.random.shuffle(random_order)\n",
    "        aaaa = [aaaa[i] for i in random_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 3, 1]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2predicate = {i:j for i,j in enumerate(sorted(allow_relation))}\n",
    "predicate2id = {j:i for i,j in id2predicate.items()}\n",
    "\n",
    "\n",
    "with codecs.open('./歌曲相关/rel2id.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump([id2predicate, predicate2id], f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('./歌曲相关/train_triples.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_train_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "with codecs.open('./歌曲相关/dev_triples.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_test_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "with codecs.open('./歌曲相关/test_triples.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_test_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('./歌曲相关/test_triples.json', 'r', encoding='utf-8') as f:\n",
    "    new_test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36294"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"lh_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"D:\\workplace\\模型总结\\命名实体识别\\Bert_lstm_实体识别_new\\entity_list.pkl\", \"rb\") as f:\n",
    "    a = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def find_head_idx(source, target):\n",
    "        target_len = len(target)\n",
    "        for i in range(len(source)):\n",
    "            if source[i: i + target_len] == target:\n",
    "                return i\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "        res_list = []\n",
    "        for data in a:\n",
    "            text = data[\"text\"]\n",
    "            s_list = []\n",
    "            o_list = []\n",
    "\n",
    "            predict_list = data[\"predict\"]\n",
    "            s_allow_list = [\"人物\"]\n",
    "            o_allow_list = [\"Date\",\"地点\",\"国家\",\"学校\"]\n",
    "            for key,values in predict_list.items():\n",
    "                if key in s_allow_list:\n",
    "                    for value in values:\n",
    "                        if value not in s_list:\n",
    "                            s_list.append(value)\n",
    "                if key in o_allow_list:\n",
    "                    for value in values:\n",
    "                        if value not in o_list:\n",
    "                            o_list.append(value)\n",
    "\n",
    "            for s1 in s_list:\n",
    "                for o1 in o_list:\n",
    "                    s = copy.deepcopy(s1)\n",
    "                    o = copy.deepcopy(o1)\n",
    "                    s_index = find_head_idx(text, s)\n",
    "                    o_index = find_head_idx(text, o)\n",
    "                    one_text = copy.deepcopy(text)\n",
    "                    if s_index < o_index:\n",
    "                        one_text.insert(s_index, \"$\")\n",
    "                        one_text.insert(s_index + len(s) + 1, \"$\")\n",
    "                        one_text.insert(o_index + 2, \"#\")\n",
    "                        one_text.insert(o_index + len(o) + 3, \"#\")\n",
    "                        s = [\"$\"] + s + [\"$\"]\n",
    "                        o = [\"#\"] + o + [\"#\"]\n",
    "                    else:\n",
    "                        one_text.insert(o_index, \"#\")\n",
    "                        one_text.insert(o_index + len(o) + 1, \"#\")\n",
    "                        one_text.insert(s_index + 2, \"$\")\n",
    "                        one_text.insert(s_index + len(s) + 3, \"$\")\n",
    "                        o = [\"#\"] + o + [\"#\"]\n",
    "                        s = [\"$\"] + s + [\"$\"]\n",
    "                    one_text = \"\".join(one_text[1:])\n",
    "                    ss = \"\".join(s)\n",
    "                    oo = \"\".join(o)\n",
    "                    one_text = \"\".join(one_text.split())\n",
    "                    ss = \"\".join(ss.split())\n",
    "                    oo = \"\".join(oo.split())\n",
    "                    res_list.append([ss, oo, \"人物/学校/毕业院校\", one_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$鲁昭公$', '#前560年#', '人物/学校/毕业院校', '$鲁昭公$（#前560年#—前510年），姬姓，名裯，一名稠、袑，鲁襄公之子，母齐归，春秋时期鲁国第二十四位国君，前542年―前510年在位']\n",
      "['$鲁昭公$', '#鲁#', '人物/学校/毕业院校', '#鲁$#昭公$（前560年—前510年），姬姓，名裯，一名稠、袑，鲁襄公之子，母齐归，春秋时期鲁国第二十四位国君，前542年―前510年在位']\n"
     ]
    }
   ],
   "source": [
    "for i in res_list:\n",
    "    if \"一名稠、袑\" in i[3]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$武先录$',\n",
       " '#1941#',\n",
       " '人物/学校/毕业院校',\n",
       " '$武先录$#1941#年生，陕西绥德县人，榆林地区卫校毕业，任陕西靖边县中医院二门诊针灸副主任医师，兼任中国针灸学会会员']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['[CLS]',\n",
       "  '让',\n",
       "  '小',\n",
       "  '编',\n",
       "  '来',\n",
       "  '给',\n",
       "  '你',\n",
       "  '恶',\n",
       "  '补',\n",
       "  '一',\n",
       "  '下',\n",
       "  '：',\n",
       "  '孙',\n",
       "  '佳',\n",
       "  '奇',\n",
       "  '，',\n",
       "  '1',\n",
       "  '9',\n",
       "  '9',\n",
       "  '2',\n",
       "  '年',\n",
       "  '2',\n",
       "  '月',\n",
       "  '1',\n",
       "  '0',\n",
       "  '日',\n",
       "  '出',\n",
       "  '生',\n",
       "  '于',\n",
       "  '黑',\n",
       "  '龙',\n",
       "  '江',\n",
       "  '，',\n",
       "  '中',\n",
       "  '国',\n",
       "  '内',\n",
       "  '地',\n",
       "  '女',\n",
       "  '演',\n",
       "  '员',\n",
       "  '，',\n",
       "  '毕',\n",
       "  '业',\n",
       "  '于',\n",
       "  '中',\n",
       "  '央',\n",
       "  '戏',\n",
       "  '剧',\n",
       "  '学',\n",
       "  '院',\n",
       "  '表',\n",
       "  '演',\n",
       "  '系'],\n",
       " 'triple_list': [[['孙', '佳', '奇'],\n",
       "   '人物/学校/毕业院校',\n",
       "   ['中', '央', '戏', '剧', '学', '院']],\n",
       "  [['孙', '佳', '奇'],\n",
       "   '人物/Date/出生日期',\n",
       "   ['1', '9', '9', '2', '年', '2', '月', '1', '0', '日']]],\n",
       " 'predict': {'人物': [['孙', '佳', '奇']],\n",
       "  'Date': [['1', '9', '9', '2', '年', '2', '月', '1', '0', '日']],\n",
       "  '地点': [['黑', '龙', '江']],\n",
       "  '国家': [['中', '国']],\n",
       "  '学校': [['中', '央', '戏', '剧', '学', '院']]}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_head_idx(source, target):\n",
    "    target_len = len(target)\n",
    "    for i in range(len(source)):\n",
    "        if source[i: i + target_len] == target:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23323"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_head_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d74e74de4d58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[0mnew_triple_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"无关\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_triple_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0ms_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_head_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mo_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_head_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mone_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'find_head_idx' is not defined"
     ]
    }
   ],
   "source": [
    "all_list = []\n",
    "for data in all_data:\n",
    "    text = data[\"text\"]\n",
    "    s_list = []\n",
    "    o_list = []\n",
    "    so_list = []\n",
    "    res_list = []\n",
    "    new_triple_list = data[\"triple_list\"]\n",
    "    for s, r, o in data[\"triple_list\"]:\n",
    "        if s not in s_list:\n",
    "            s_list.append(s)\n",
    "        if o not in o_list:\n",
    "            o_list.append(o)\n",
    "        if [s, o] not in so_list:\n",
    "            so_list.append([s, o])\n",
    "    for s in s_list:\n",
    "        for o in o_list:\n",
    "            if s != o:\n",
    "                if [s, o] not in so_list:\n",
    "                    new_triple_list.append([s, \"无关\", o])\n",
    "    for s, r, o in new_triple_list:\n",
    "        s_index = find_head_idx(text, s)\n",
    "        o_index = find_head_idx(text, o)\n",
    "        one_text = copy.deepcopy(text)\n",
    "#         if s_index > o_index and r != \"无关\":\n",
    "#             r_split = r.split(\"/\")\n",
    "#             r = \"/\".join([r_split[1], r_split[0], r_split[2]])\n",
    "        if s_index < o_index:\n",
    "            one_text.insert(s_index, \"$\")\n",
    "            one_text.insert(s_index + len(s) + 1, \"$\")\n",
    "            one_text.insert(o_index + 2, \"#\")\n",
    "            one_text.insert(o_index + len(o) + 3, \"#\")\n",
    "        else:\n",
    "            one_text.insert(o_index, \"$\")\n",
    "            one_text.insert(o_index + len(o) + 1, \"$\")\n",
    "            one_text.insert(s_index + 2, \"#\")\n",
    "            one_text.insert(s_index + len(s) + 3, \"#\")\n",
    "        one_text = \"\".join(one_text)\n",
    "        res_list.append([one_text, r])\n",
    "    all_list += res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87305"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"aaa.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44569.600000000006"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55712*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "44569.0//64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.0625"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5700/64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36480//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4035087719298245"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8000/5700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18658"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = []\n",
    "for data in new_train_data:\n",
    "    text = data[\"text\"]\n",
    "    s_list = []\n",
    "    o_list = []\n",
    "    so_list = []\n",
    "    res_list = []\n",
    "    new_triple_list = data[\"triple_list\"]\n",
    "    for s, r, o in data[\"triple_list\"]:\n",
    "        if s not in s_list:\n",
    "            s_list.append(s)\n",
    "        if o not in o_list:\n",
    "            o_list.append(o)\n",
    "        if [s, o] not in so_list:\n",
    "            so_list.append([s, o])\n",
    "    for s in s_list:\n",
    "        for o in o_list:\n",
    "            if s != o:\n",
    "                if [s, o] not in so_list:\n",
    "                    new_triple_list.append([s, \"无关\", o])\n",
    "    for s, r, o in new_triple_list:\n",
    "#         if r not in [\"人物/人物/丈夫\",\"人物/人物/妻子\",\"人物/地点/祖籍\",\"人物/国家/国籍\"]:\n",
    "#             continue\n",
    "        s_index = find_head_idx(text, s)\n",
    "        o_index = find_head_idx(text, o)\n",
    "        one_text = copy.deepcopy(text)\n",
    "#         if s_index > o_index and r != \"无关\":\n",
    "#             r_split = r.split(\"/\")\n",
    "#             r = \"/\".join([r_split[1], r_split[0], r_split[2]])\n",
    "        if s_index < o_index:\n",
    "            one_text.insert(s_index, \"$\")\n",
    "            one_text.insert(s_index + len(s) + 1, \"$\")\n",
    "            one_text.insert(o_index + 2, \"#\")\n",
    "            one_text.insert(o_index + len(o) + 3, \"#\")\n",
    "            s = [\"$\"]+s+[\"$\"]\n",
    "            o = [\"#\"]+o+[\"#\"]\n",
    "        else:\n",
    "            one_text.insert(o_index, \"#\")\n",
    "            one_text.insert(o_index + len(o) + 1, \"#\")\n",
    "            one_text.insert(s_index + 2, \"$\")\n",
    "            one_text.insert(s_index + len(s) + 3, \"$\")\n",
    "            o = [\"#\"]+o+[\"#\"]\n",
    "            s = [\"$\"]+s+[\"$\"]\n",
    "        one_text = \"\".join(one_text)\n",
    "        ss = \"\".join(s)\n",
    "        oo = \"\".join(o)\n",
    "        one_text = \"\".join(one_text.split())\n",
    "        ss = \"\".join(ss.split())\n",
    "        oo = \"\".join(oo.split())\n",
    "        res_list.append([ss,oo,r,one_text])\n",
    "    all_list += res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_list = []\n",
    "for data in new_test_data:\n",
    "    text = data[\"text\"]\n",
    "    s_list = []\n",
    "    o_list = []\n",
    "    so_list = []\n",
    "    res_list = []\n",
    "    new_triple_list = data[\"triple_list\"]\n",
    "    for s, r, o in data[\"triple_list\"]:\n",
    "        if s not in s_list:\n",
    "            s_list.append(s)\n",
    "        if o not in o_list:\n",
    "            o_list.append(o)\n",
    "        if [s, o] not in so_list:\n",
    "            so_list.append([s, o])\n",
    "    for s in s_list:\n",
    "        for o in o_list:\n",
    "            if s != o:\n",
    "                if [s, o] not in so_list:\n",
    "                    new_triple_list.append([s, \"无关\", o])\n",
    "    for s, r, o in new_triple_list:\n",
    "#         if r not in [\"人物/人物/丈夫\",\"人物/人物/妻子\",\"人物/地点/祖籍\",\"人物/国家/国籍\"]:\n",
    "#             continue\n",
    "        s_index = find_head_idx(text, s)\n",
    "        o_index = find_head_idx(text, o)\n",
    "        one_text = copy.deepcopy(text)\n",
    "#         if s_index > o_index and r != \"无关\":\n",
    "#             r_split = r.split(\"/\")\n",
    "#             r = \"/\".join([r_split[1], r_split[0], r_split[2]])\n",
    "        if s_index < o_index:\n",
    "            one_text.insert(s_index, \"$\")\n",
    "            one_text.insert(s_index + len(s) + 1, \"$\")\n",
    "            one_text.insert(o_index + 2, \"#\")\n",
    "            one_text.insert(o_index + len(o) + 3, \"#\")\n",
    "            s = [\"$\"]+s+[\"$\"]\n",
    "            o = [\"#\"]+o+[\"#\"]\n",
    "        else:\n",
    "            one_text.insert(o_index, \"#\")\n",
    "            one_text.insert(o_index + len(o) + 1, \"#\")\n",
    "            one_text.insert(s_index + 2, \"$\")\n",
    "            one_text.insert(s_index + len(s) + 3, \"$\")\n",
    "            o = [\"#\"]+o+[\"#\"]\n",
    "            s = [\"$\"]+s+[\"$\"]\n",
    "        one_text = \"\".join(one_text)\n",
    "        ss = \"\".join(s)\n",
    "        oo = \"\".join(o)\n",
    "        one_text = \"\".join(one_text.split())\n",
    "        ss = \"\".join(ss.split())\n",
    "        oo = \"\".join(oo.split())\n",
    "        res_list.append([ss,oo,r,one_text])\n",
    "    test_all_list += res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11215"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44497"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_all_list = all_list + test_all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$是我不小心$', '#陈明#', '歌曲/人物/歌手', '《$是我不小心$》是#陈明#演唱的一首歌曲，收录在专辑《相信你总会被我感动》当中']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$直线$',\n",
       " '#大飞#',\n",
       " '歌曲/人物/作词',\n",
       " '歌曲介绍由#大飞#作词，深白色作曲，吕绍淳编曲的歌曲《$直线$》，属于专辑中深具爆发力的一首歌曲']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_list[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$美丽心情$', '#姚谦#', '歌曲/人物/作词', '$美丽心情$演唱：叶一茜词:#姚谦#曲:中岛美雪lrc制作：酷我歌词组']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$龙卷风$', '#周杰伦#', '歌曲/人物/歌手', '#周杰伦#的《告白气球》、《$龙卷风$》《明明就》等等歌曲都是我常伴我的良友']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11142.400000000001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55712*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"att_lstm_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(a_all_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$别再说$', '#寂寞缠绕#', '歌曲/音乐专辑/所属专辑', '《$别再说$》是小露的音乐作品，顾峰作曲，收录在《#寂寞缠绕#》专辑中']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_all_list[44496]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$留白$',\n",
       " '#robertlay#',\n",
       " '歌曲/人物/作曲',\n",
       " '《$留白$》是由王仲杰作词，#robertlay#作曲，韦景云编曲，许廷铿演唱的一首歌曲，收录于专辑《出走三部曲》中，发行于2011年06月28日']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44012.48"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55712*0.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55712"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def parse_data(all_data,max_seq_length):\n",
    "        all_list = []\n",
    "        n = 0\n",
    "        for data in all_data:\n",
    "            text = list(data[3])\n",
    "            s = list(data[0])\n",
    "            o = list(data[1])\n",
    "            # if \"$\" in data[0]:\n",
    "            #     s = list(data[0])\n",
    "            #     o = list(data[1])\n",
    "            # else:\n",
    "            #     s = list(data[1])\n",
    "            #     o = list(data[0])\n",
    "            relation = data[2]\n",
    "            s_index = find_head_idx(text, s)\n",
    "            o_index = find_head_idx(text, o)\n",
    "            one_text = copy.deepcopy(text)\n",
    "\n",
    "            if s_index == -1 or o_index == -1:\n",
    "                n += 1\n",
    "                print(11111111111111111111111)\n",
    "                continue\n",
    "\n",
    "            one_text.insert(s_index, \" a1 \")\n",
    "            one_text.insert(s_index + len(s) + 1, \" a2 \")\n",
    "            one_text.insert(o_index + 2, \" b1 \")\n",
    "            one_text.insert(o_index + len(o) + 3, \" b2 \")\n",
    "\n",
    "            # if s_index < o_index:\n",
    "            #     one_text.insert(s_index, \" a1 \")\n",
    "            #     one_text.insert(s_index + len(s) + 1, \" a2 \")\n",
    "            #     one_text.insert(o_index + 2, \" b1 \")\n",
    "            #     one_text.insert(o_index + len(o) + 3, \" b2 \")\n",
    "            # else:\n",
    "            #     one_text.insert(o_index, \" a1 \")\n",
    "            #     one_text.insert(o_index + len(o) + 1, \" a2 \")\n",
    "            #     one_text.insert(s_index + 2, \" b1 \")\n",
    "            #     one_text.insert(s_index + len(s) + 3, \" b2 \")\n",
    "            one_text = \"\".join(one_text)\n",
    "            if len(one_text) > max_seq_length-6:\n",
    "                continue\n",
    "            all_list.append([one_text, relation])\n",
    "        print(n)\n",
    "        return all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "        random.seed(1)\n",
    "        random.shuffle(all_list)\n",
    "        data_len = len(all_list)\n",
    "        train = int(data_len * 0.8)\n",
    "        train_data = all_list[:train]\n",
    "        test_data = all_list[train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['$请你不要爱我$',\n",
       "  '#周子寒#',\n",
       "  '歌曲/人物/歌手',\n",
       "  '歌曲：$请你不要爱我$歌手：#周子寒#所属专辑：《听说你离开他》发行时间：1990年关于歌曲：听子寒的歌，就像是一幅感情的心电图，记录着你我心绪的起伏与波动，写满着你我情爱的曲折与弯延，这样植入人心的音乐，我们称它为心灵音乐'],\n",
       " ['$离不开你$', '#朱一工#', '歌曲/人物/作词', '《$离不开你$》是歌手黄绮珊演唱，#朱一工#作词，刘欢作曲的一首歌曲'],\n",
       " ['$斯皮克斯$',\n",
       "  '#卢巧音#',\n",
       "  '歌曲/人物/歌手',\n",
       "  '《$斯皮克斯$》是#卢巧音#演唱的歌曲，由启伦填词，傅佩嘉谱曲，收录于专辑《nuri》'],\n",
       " ['$有故事的人$',\n",
       "  '#李宗盛#',\n",
       "  '无关',\n",
       "  '《最近比较烦》是由#李宗盛#作词作曲，周华健、李宗盛和品冠演唱的一首歌，收录于专辑《$有故事的人$》中'],\n",
       " ['$爱从草原来$', '#乌兰托娅#', '歌曲/人物/歌手', '1歌曲《我的西藏》是由歌手#乌兰托娅#演唱的一首歌曲，所属专辑《$爱从草原来$》'],\n",
       " ['$疯狂的世界$',\n",
       "  '#王胜男#',\n",
       "  '歌曲/人物/作曲',\n",
       "  '《电力火车》是#王胜男#演唱的歌曲，收录于王胜男于2015年发行的专辑《$疯狂的世界$》中'],\n",
       " ['$我的祖国$', '#郭兰英#', '歌曲/人物/歌手', '《敢叫日月换新天》是#郭兰英#演唱的歌曲，收录于《$我的祖国$》-演唱全集⑤'],\n",
       " ['$我唱我歌$',\n",
       "  '#杨湘粤#',\n",
       "  '歌曲/人物/作词',\n",
       "  '《$我唱我歌$》是由著名歌手叶世荣、海鸣威、黄山怡（糖妹）、刘仙露演唱的歌曲，该曲由香港著名填词人、资深音乐人向雪怀和广东知名作词人#杨湘粤#联手填词，音乐人秋言作曲'],\n",
       " ['$会过去的$',\n",
       "  '#优先拥抱#',\n",
       "  '歌曲/音乐专辑/所属专辑',\n",
       "  '在这张最新粤语专辑《#优先拥抱#》中，除了收录大热歌曲「$会过去的$」之外，还有安仔参与作曲的「七年滋养」，主打歌「只会深爱你」、「借你耳朵说爱你」等许志安最擅长的抒情慢歌，绝对好听耐听'],\n",
       " ['$我管你$',\n",
       "  '#华晨宇#',\n",
       "  '歌曲/人物/歌手',\n",
       "  '欢迎收看本期的歌单：（歌单）本期的花花带来了他的另一首原创作品《$我管你$》，这首收录在专辑《异类》中的歌曲，是#华晨宇#自己创作的另类摇滚作品，颇具层次的听觉感受，搭配酷炫狂拽的歌词，估计又要收割一波迷妹啦']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11143"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "11111111111111111111111\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "aaa = parse_data(test_all_list,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10753"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['《 a1 $狼狈$ a2 》是欢子为2011流行音乐再次画出最亮丽的一笔，推出全新专辑《 b1 #我们回不去了# b2 》里的歌曲',\n",
       " '歌曲/音乐专辑/所属专辑']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
