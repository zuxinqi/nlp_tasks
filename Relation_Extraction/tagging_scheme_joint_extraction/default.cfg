[DEFAULT]
uerdict_path = ./userdict.txt
stopwords_path = ./stopwords.txt
tokenizer_name = single
[DATA_PROCESS]
file_path = ../数据准备/lic2019_relation_extraction_data.pkl
save_path = ./TSJRE_lic2019.pkl
vocab_file = /root/zxq/ner_extract/Bert+crf/chinese_roberta_wwm_ext_L-12_H-768_A-12/vocab.txt
max_seq_length = 132
[MODEL]
max_seq_length = 132
bert_config_file = /root/zxq/ner_extract/Bert+crf/chinese_roberta_wwm_ext_L-12_H-768_A-12/bert_config.json
init_checkpoint = /root/zxq/ner_extract/Bert+crf/chinese_roberta_wwm_ext_L-12_H-768_A-12/bert_model.ckpt
use_lstm = True
hidden_size = 128
cell_nums = 2
use_lstm_dropout = True
lstm_dropout = 0.9
embedding_dropout = 0.9
learning_rate = 5e-5
is_training = True
num_train_epochs = 30
batch_size = 16
shuffle = True
warmup_proportion = 0.1
display_per_step = 100
evaluation_per_step = 500
require_improvement = 5