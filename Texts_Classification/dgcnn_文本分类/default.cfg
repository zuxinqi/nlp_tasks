[DEFAULT]
uerdict_path = ./userdict.txt
stopwords_path = ./stopwords.txt
tokenizer_name = single
[DATA_PROCESS]
file_path = ../数据准备/toutiao_all_data.pkl
save_path = ./TC_classfication.pkl
word2vec_embed_file = /root/zxq/Tencent_AILab_ChineseEmbedding.txt
fasttext_embed_file = /root/zxq/cc.zh.300.bin
feature_selection_name = word2vec
[MODEL]
max_seq_length = 100
filter_size = 300
is_training = True
update_embedding = True
filters = 600
hidden_num = 64
use_l2_regularization = False
learning_rate = 0.0001
use_decay_learning_rate = False
num_train_epochs = 60
batch_size = 64
shuffle = True
dropout_rate = 0.6
display_per_step = 100
evaluation_per_step = 500
require_improvement = 60