[DEFAULT]
uerdict_path = ./userdict.txt
stopwords_path = ./stopwords.txt
tokenizer_name = single
[DATA_PROCESS]
file_path = ../数据准备/toutiao_all_data.pkl
save_path = ./RCNN_classfication.pkl
word2vec_embed_file = /root/zxq/Tencent_AILab_ChineseEmbedding.txt
fasttext_embed_file = /root/zxq/cc.zh.300.bin
feature_selection_name = word2vec
[MODEL]
max_seq_length = 100
lstm_hidden_size = 500
cell_nums = 1
is_training = True
update_embedding = False
hidden_num = 128
use_l2_regularization = False
learning_rate = 0.001
use_decay_learning_rate = False
num_train_epochs = 50
batch_size = 128
shuffle = True
dropout_rate = 0.8
display_per_step = 100
evaluation_per_step = 500
require_improvement = 5